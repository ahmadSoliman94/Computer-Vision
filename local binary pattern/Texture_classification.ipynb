{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open source implementation of LBP\n",
    "from skimage.feature import local_binary_pattern\n",
    "# data preprocessing and metrics module in scikit-learn\n",
    "from sklearn import preprocessing, metrics\n",
    "# SVM implementation in scikit-learn\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doonload_data(file, url):\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if not os.path.exists(file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        \n",
    "        # Download the file from the specified URL\n",
    "        urllib.request.urlretrieve(url, file)\n",
    "\n",
    "        # Extract the contents of the downloaded file into 'data' directory\n",
    "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "            zip_ref.extractall('data')\n",
    "        \n",
    "        # Remove the downloaded zip file\n",
    "        os.remove(file)\n",
    "\n",
    "        print('Done!')\n",
    "    else:\n",
    "        print(file + ' already exists.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading s3_photos.zip...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "file = 's3_photos.zip'\n",
    "url = 'http://apmonitor.com/pds/uploads/Main/'+file\n",
    "\n",
    "# Download the data file\n",
    "doonload_data(file, url)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local binary pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp(arr):\n",
    "\n",
    "    \"\"\"\n",
    "    Find the local binary pattern representation of the given image.\n",
    "    Peform Vectorization/Normalization of the image to get feature vector.\n",
    "    \"\"\"\n",
    "\n",
    "    # parameters for LBP\n",
    "    radius = 1\n",
    "    n_points = 8 * radius\n",
    "    n_bins = n_points + 2 # number of neighbors n_points + 2 (for center pixel + 2)\n",
    "    lbp = local_binary_pattern(arr, n_points, radius, method='uniform') # LBP representation\n",
    "    lbp = lbp.ravel() # vectorization: convert 2D array to 1D array\n",
    "    \n",
    "    # normalization \n",
    "    feature = np.zeros(n_bins) # initialize feature vector\n",
    "    for i in lbp:\n",
    "        feature[int(i)] += 1 # count the number of occurences of each value\n",
    "    feature /= np.linalg.norm(feature) # normalize the feature vector\n",
    "    return feature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(tag='data/train'):\n",
    "\n",
    "    \"\"\"\n",
    "    Load the data from the given directory.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    tag_dir = Path.cwd() / tag # path to the directory\n",
    "    vec = [] # list of feature vectors\n",
    "    cat = [] # list of categories\n",
    "    for cat_dir in tag_dir.iterdir(): # iterate over the subdirectories\n",
    "        cat_label = cat_dir.stem # get the name of the subdirectory\n",
    "        for img_path in cat_dir.glob('*.png'): # iterate over the images in the subdirectory\n",
    "            img = Image.open(img_path.as_posix()) # open the image\n",
    "            if img.mode != 'L': # convert the image to grayscale if it is not already\n",
    "                img = ImageOps.grayscale(img) # convert the image to grayscale\n",
    "                img.save(img_path.as_posix())  # save the image, img_path.as_posix() returns the path as a string\n",
    "            arr = np.array(img) # convert the image to numpy array\n",
    "            feature = compute_lbp(arr) # compute the feature vector\n",
    "            vec.append(feature) # append the feature vector to the list of feature vectors\n",
    "            cat.append(cat_label) # append the category to the list of categories\n",
    "    return vec, cat\n",
    "\n",
    "# train photos\n",
    "vec_train, cat_train = load_data('data/train')\n",
    "# test photos\n",
    "vec_test, cat_test   = load_data('data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sand', 'Seed', 'Stone']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the unique categories\n",
    "lables = list(np.unique(np.array(cat_train)))\n",
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "label_train = le.fit_transform(cat_train)\n",
    "label_test = le.transform(cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(vec_train, label_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
